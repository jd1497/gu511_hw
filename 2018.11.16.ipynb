{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises due by EOD 2018.11.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this homework assignment we will utilize the `aws` `cli`, the `boto3` `python` sdk, and the `s3` service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method of delivery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as mentioned in our first lecture, the method of delivery may change from assignment to assignment. we will include this section in every assignment to provide an overview of how we expect homework results to be submitted, and to provide background notes or explanations for \"new\" delivery concepts or methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this week you will be submitting the results of your homework via an email to **BOTH** Zach (rzl5@georgetown.edu) and Carlos (chb49@georgetown.edu) titled \"2018.11.16 answers\", uploading files to an `s3`, and commits to your `gu511_git_hw` on `github`\n",
    "\n",
    "summary:\n",
    "\n",
    "| exercise | deliverable | method of delivery |\n",
    "|----------|-------------|--------------------|\n",
    "| 1 | an `s3` bucket name | include in your submission email |\n",
    "| 2 | none | none |\n",
    "| 3 | a file `iam.py` | uploaded to your `s3` homework submission bucket |\n",
    "| 4 | a file `spot_price_history.ipynb` | uploaded to your `s3` homework submission bucket |\n",
    "| 5 | your `aws` \"canonical id\" value | include in your submission email |\n",
    "| 6 | the publically available `url` of your `s3`-hosted static webpage | include in your submission email |\n",
    "| 7 | the publically available `url` of an \"alarm clock\" message | include in your submission email |\n",
    "| 7 | a `bash` command for running `alarm_clock.py` | include in your submission email |\n",
    "| 8 | a file `clientside.py` | uploaded to your `s3` homework submission bucket |\n",
    "| 9 | two commits on your `master` branch | pushed to `github` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 1: create an `s3` bucket for homework submission\n",
    "\n",
    "<span style=\"color:red;font-weight:bold\">UPDATE: the interface for creating buckets [has changed](https://docs.aws.amazon.com/AmazonS3/latest/dev/WhatsNew.html). the previous behavior is available via checking out previous `git` commits</span>\n",
    "\n",
    "\n",
    "## .1 create a new `s3` bucket\n",
    "\n",
    "1. call it whatever you want\n",
    "1. leave all other permissions alone\n",
    "\n",
    "\n",
    "## .2: grant us *bucket* permissions\n",
    "\n",
    "after that bucket has been created:\n",
    "\n",
    "1. open the `s3` web console page for the bucket you just created\n",
    "1. grant my `aws` account *bucket* permissions (for listing files, mostly)\n",
    "    1. click on the \"Permissions\" tab\n",
    "    1. click on the \"Access Control List\" button\n",
    "    1. click the \"+ add account\" button\n",
    "    1. add my email address (`rzl5@georgetown.edu`) and check all four boxes\n",
    "    1. click \"Save\"\n",
    "\n",
    "<br><div align=\"center\"><img src=\"http://drive.google.com/uc?export=view&id=1wokO60WWYXtxhVrFF0VZBoGUgywmKZv5\" width=\"1000\"></div>\n",
    "\n",
    "\n",
    "## .3: grant us *file* permissions within that bucket\n",
    "\n",
    "continue in the \"Permissions\" tab and do the following:\n",
    "\n",
    "1. open the `s3` web console page for the bucket you just created\n",
    "1. click on the \"Permissions\" tab\n",
    "1. click the \"Bucket Policy\" button -- you should see an editor\n",
    "1. click the \"policy generator\" link at the bottom of the editor\n",
    "1. generate a policy\n",
    "    1. change \"Select Type of Policy\" to \"S3 Bucket Policy\"\n",
    "    1. Principal = 134461086921\n",
    "    1. AWS Service = Amazon S3\n",
    "    1. Actions = click the \"All Actions\" button\n",
    "    1. Amazon Resource Name (ARN) = `arn:aws:s3:::YOUR_BUCKET_NAME_HERE,arn:aws:s3:::YOUR_BUCKET_NAME_HERE/*` (replace both instances of `YOUR_BUCKET_NAME_HERE` with the simple bucket name\n",
    "        + note that the above is *two* `arn` values separated by a comma, the first is the `arn` of the bucket, and the second is an `arn` matching the path of any key in that bucket. *both* are necessary.\n",
    "        + for example, my value is `arn:aws:s3:::testshare.lamberty.io,arn:aws:s3:::testshare.lamberty.io/*`\n",
    "    1. click Add Statement\n",
    "    1. click \"Generate Policy\"\n",
    "    1. copy the pop-up's contents\n",
    "1. back on the previous policy editor page, in the editor field, paste the `json` policy you just generated and copied\n",
    "1. click \"Save\"\n",
    "\n",
    "<br><div align=\"center\"><img src=\"http://drive.google.com/uc?export=view&id=1w-St2yR_2Rls6OPngnFSWc1vpf0Dw2xG\" width=\"700\"></div>\n",
    "\n",
    "\n",
    "what you generate in the \"generate policy\" step should look like the text below:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"Id\": \"Policy1542229407821\",\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Sid\": \"Stmt1542229397978\",\n",
    "      \"Action\": \"s3:*\",\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Resource\": [\n",
    "        \"arn:aws:s3:::testshare.lamberty.io\",\n",
    "        \"arn:aws:s3:::testshare.lamberty.io/*\"\n",
    "      ],\n",
    "      \"Principal\": {\n",
    "        \"AWS\": [\n",
    "          \"134461086921\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "this has the effect of allowing our AWS account to have full permissions on your *files* instead of just the bucket.\n",
    "\n",
    "\n",
    "## >> going forward, I will refer to this as your \"`s3` homework submission bucket\" <<\n",
    "\n",
    "##### include the name of your bucket `s3://xxxxxxxxxxxx` in your submission email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 2: using `aws boto3` on your local laptop\n",
    "\n",
    "in class, we created an `iam role` for our `ec2` servers, and the permissions which are granted to that `iam role` are the permissions we have when using `boto3` on that server.\n",
    "\n",
    "in one of the below steps, you *must* be using your local laptop -- that `iam role` does not apply to you in that case!\n",
    "\n",
    "in order to use `boto3` from your local laptop, you will need to install it, and then authenticate with the access keys associated with your `iam` account. to do this, you must:\n",
    "\n",
    "1. install `boto3` via `conda install boto3` on your local laptop\n",
    "1. get your `iam` account access key id and value\n",
    "    1. you can get these via the `iam` web console, the `csv` file you already saved, or the credentials file on your `ec2` instance `~/.aws/credentials`\n",
    "1. use those credentials when authenticating (see below)\n",
    "    \n",
    "assuming you have your credentials, there are two ways you can authenticate. first, you could create a profile, and in `boto3` always use profiles:\n",
    "\n",
    "```sh\n",
    "aws configure --profile your_profile_name\n",
    "# enter the id\n",
    "# enter the secret\n",
    "# enter us-east-1\n",
    "# just press enter (don't write anything)\n",
    "```\n",
    "\n",
    "and then in a `python` session\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "session = boto3.session.Session(profile_name='your_profile_name')\n",
    "```\n",
    "\n",
    "**alternatively**, you could directly pass your access key and secret information to the session when you create it (that is, never create a profile). in a `python` session this would look like\n",
    "\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id='YOUR_AWS_ACCESS_KEY_ID',\n",
    "    aws_secret_access_key='YOUR_AWS_SECRET_ACCESS_KEY',\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "```\n",
    "\n",
    "which of these two you want to do is up to you!\n",
    "\n",
    "##### there is nothing to submit for this exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 3: using `aws` `boto3` to acquire basic information\n",
    "\n",
    "complete all incomplete parts of the following three functions. save these functions in a file `iam.py`.\n",
    "\n",
    "in order to be able to *run* this code on your `ec2` instance (which you will probably want to do, for debugging purposes), you will need to add either the `IAMReadOnlyAccess` or `IAMFullAccess` policy to *whatever* account you are authenticating with, e.g.\n",
    "\n",
    "+ if you are running code on your `ec2` instance and added an `IAM` service `role` to that instance, you should add that policy to that service `role`\n",
    "+ if you are using a `default` configuration and authentication keys associated with a user (e.g. `gu511`, or your personal user), you should add that policy to that `user` or a `group` that `user` is in \n",
    "\n",
    "```python\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Module: iam.py\n",
    "\n",
    "Description:\n",
    "    generate lists of users, roles, and groups from the `iam` service\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import boto3\n",
    "\n",
    "\n",
    "def get_users():\n",
    "    # create a boto3 session object\n",
    "    session = boto3.session.Session()\n",
    "    \n",
    "    # create an iam resource object\n",
    "    iam = session.resource('iam')\n",
    "    \n",
    "    # iterate over all `iam users` and extract the \n",
    "    # `name` member into a list\n",
    "    names = [\n",
    "        user.name\n",
    "        for user in iam.users.all()\n",
    "    ]\n",
    "    \n",
    "    return names\n",
    "    \n",
    "    \n",
    "def get_roles():\n",
    "    # createa boto3 session object\n",
    "    # --------------- #\n",
    "    # FILL ME IN !!!! #\n",
    "    # --------------- #\n",
    "    \n",
    "    # create an iam resource object\n",
    "    # --------------- #\n",
    "    # FILL ME IN !!!! #\n",
    "    # --------------- #\n",
    "    \n",
    "    # iterate over all `iam roles` and extract the \n",
    "    # `name` member into a list\n",
    "    # --------------- #\n",
    "    # FILL ME IN !!!! #\n",
    "    # --------------- #\n",
    "    \n",
    "    return roles\n",
    "    \n",
    "    \n",
    "def get_groups():\n",
    "    # createa boto3 session object\n",
    "    # --------------- #\n",
    "    # FILL ME IN !!!! #\n",
    "    # --------------- #\n",
    "    \n",
    "    # create an iam resource object\n",
    "    # --------------- #\n",
    "    # FILL ME IN !!!! #\n",
    "    # --------------- #\n",
    "    \n",
    "    # iterate over all `iam groups` and extract the \n",
    "    # `name` member into a list\n",
    "    # --------------- #\n",
    "    # FILL ME IN !!!! #\n",
    "    # --------------- #\n",
    "    \n",
    "    return groups  \n",
    "```\n",
    "\n",
    "##### upload `iam.py` to your `s3` homework submission bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 4: using `boto3` to get spot price history\n",
    "\n",
    "it is possible to pull spot price history for various types of machines, in various regions, and between arbitrary start and end times. In particular, it's possible to pull an entire day's worth of spot prices, all using pretty straight forward functions in the `boto3` library.\n",
    "\n",
    "download the neighboring `spot_price_history.ipynb` `jupyter` notebook file to your local laptop and launch a `jupyter` notebook server to interact with that notebook. you **must** do this on your local laptop -- `colab` will not work, as you need to have `boto3` installed and your `aws` access key credentials available to you.\n",
    "\n",
    "the notebook contains an outline of a simple `python` proces which uses `boto3` functions to download spot price information, load it into a `pandas` dataframe, and display that information using `plotly`.\n",
    "\n",
    "it also includes several code cells which simply read\n",
    "\n",
    "```python\n",
    "# --------------- #\n",
    "# FILL ME IN !!!! #\n",
    "# --------------- #\n",
    "```\n",
    "\n",
    "you should... you know... fill them in.\n",
    "\n",
    "if you have done everything correctly, the `assert` statements in that notebook should all pass without throwing `AssertionError`s.\n",
    "\n",
    "once you have filled them all in, **save** all changes\n",
    "\n",
    "##### upload `spot_price_history.ipynb` to your `s3` homework submission bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 5: getting your `aws` canonical user id\n",
    "\n",
    "`aws` has two separate unique identifiers for your account -- your aws account id (the 12-digit number we have seen on our account pages, and in our `arn`s) and a second one called your \"canonical user id\". the canonical user id is, by all accounts, an artifact of the early days of `aws`.\n",
    "\n",
    "because `s3` was among the first services, many of the steps you might go through in `s3`  to permission accounts will use this other older id (the canonical user id) instead of the account id. hooray for technical debt!!\n",
    "\n",
    "use one of the methods described [in the amazon account identifiers documentation](https://docs.aws.amazon.com/general/latest/gr/acct-identifiers.html#FindingCanonicalId) to find your account's \"canonical user id\" value.\n",
    "\n",
    "##### include your canonical id in your submission email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 6: create a static webpage\n",
    "\n",
    "let's make a webpage!\n",
    "\n",
    "\n",
    "## 6.1: get an `html` file\n",
    "\n",
    "we're going to need some `html` (hypertext markup language) for our webpage. If you have a page you really want to show off to the world, feel free to use it -- otherwise, feel free to use [our example](https://s3.amazonaws.com/shared.rzl.gu511.com/index.html). edit it. go wild.\n",
    "\n",
    "\n",
    "## 6.2: upload an `html` file\n",
    "\n",
    "you may remember, but when we were creating buckets in class we mentioned that it was possible to configure a bucket such that it could be used for \"static website hosting\". create a new bucket (name it whatever you want), and after creating it, let's configure it to host a static website.\n",
    "\n",
    "upload the `html` file from the previous step as `index.html`. when you upload it, grant public read access to it in the permissions page. we'll add an error document in a step below, but feel free to do that now if you already know what you want to do with that.\n",
    "\n",
    "leave the rest of the configurations as-is.\n",
    "\n",
    "\n",
    "## 6.3: turn your `bucket` into a webpage\n",
    "\n",
    "open your `bucket` in the `s3` web console and navigate to the properties tab. update the \"static website hosting\" card and make sure our index document is \"index.html\" and our error document is \"error.html\". copy the endpoint `url` they give you on this card.\n",
    "\n",
    "\n",
    "## 6.4: try it out\n",
    "\n",
    "navigate to that endpoint you were given while configuring the bucket to be a static webpage. what do you see?\n",
    "\n",
    "\n",
    "## 6.5: 403 errors\n",
    "\n",
    "if you missed a step along the way, the default behavior will be to return to you a `403 FORBIDDEN` error. For my bucket, for example:\n",
    "\n",
    "```\n",
    "403 Forbidden\n",
    "\n",
    "    * Code: AccessDenied\n",
    "    * Message: Access Denied\n",
    "    * RequestId: A7BA5343504C695B\n",
    "    * HostId: 7KtvPPnjmQAk2Ry4CeYn58+I1IL1+W+tV633d2/SX5c6XmIFqvewLMTUGwKxrgaY33tzlOF0jek=\n",
    "\n",
    "An Error Occurred While Attempting to Retrieve a Custom Error Document\n",
    "    * Code: AccessDenied\n",
    "    * Message: Access Denied\n",
    "```\n",
    "\n",
    "if you didn't receive this error, skip down to the next portion. otherwise:\n",
    "\n",
    "first, read [what a 403 error is](https://en.wikipedia.org/wiki/HTTP_403) (or [any `html` code](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes), for that matter). \n",
    "\n",
    "after this, read [the static website hosting documentation](https://docs.aws.amazon.com/AmazonS3/latest/dev/HowDoIWebsiteConfiguration.html) for details on how to configure permissions to allow users to access this site.\n",
    "\n",
    "*note*: the documentation tells you how to open *an entire bucket*, so keep in mind this will make all the items in the configured bucket public. It is possible to make a single file public from the file summary page, fwiw.\n",
    "\n",
    "using the information from the documentation, make sure that the endpoint you tried above (and possibly received a 403 for) is now publicly accessible\n",
    "\n",
    "\n",
    "## 6.6: add an error page\n",
    "\n",
    "locally, copy the `html` file you are using as your index page to a new file called `error.html`, and edit that new file to contain an error message. this might be as simple as replacing the text inside the header and first paragraph so that they contain warnings that a \"page is missing\" or \"this url was an error\". If you have your own `error.html` file, feel free to use that instead. just make it different in some human-readable way from the `index.html` file.\n",
    "\n",
    "upload that new `error.html` file, and then go back to the static webpage configuration for your bucket (where we *didn't* enter an `error.html` file before), and add the newly uploaded file. \n",
    "\n",
    "\n",
    "## 6.7: verify that missing pages redirect to `error.html`\n",
    "\n",
    "verify that a url that doesn't exist takes you to that `error.html` page. Take the ip address from before (for example, mine is: http://wp.rzl.gu511.com.s3-website-us-east-1.amazonaws.com/) and add a meaningless url path to the end of that. Again, for example: http://wp.rzl.gu511.com.s3-website-us-east-1.amazonaws.com/pagedontexistyo.php\n",
    "\n",
    "verify that the page that is displayed is your error page.\n",
    "\n",
    "\n",
    "## 6.8: let us see!\n",
    "\n",
    "send us the url of your static webpage. we will visit\n",
    "\n",
    "+ the path itself, and\n",
    "+ a path that doesn't exist (e.g. the `http://your.url.at.amazonaws.com/pagedontexistyo.php`)\n",
    "\n",
    "to verify that both the index and error pages are available.\n",
    "\n",
    "\n",
    "##### include your `url` in the body of your submission email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 7: a really sad alarm clock\n",
    "\n",
    "\n",
    "## 7.1: getting familiar with the script\n",
    "\n",
    "download [this `python` file](https://s3.amazonaws.com/shared.rzl.gu511.com/alarm_clock.py) and review it to figure out what it does.\n",
    "\n",
    "the elements below the `command line` comment block implement a command line interface (`cli`) for this python script. check out the `cli` options by trying out\n",
    "\n",
    "```bash\n",
    "python alarm_clock.py --help\n",
    "```\n",
    "\n",
    "*note*: this file has `boto3` as a prerequisite, so you have to execute the above command in an environment where `boto3` is installed. additionally, it assumes a `default` profile exists, or an `iam` role for an `ec2` server that it is running on, so make sure those exist as well.\n",
    "\n",
    "\n",
    "## 7.2: create an alarm clock bucket\n",
    "\n",
    "create a *new* `s3` bucket (i.e. don't use your homework submission `s3` bucket) and make it fully visible to the public.\n",
    "\n",
    "going forward, I will refer to this as \"the alarm clock bucket\".\n",
    "\n",
    "\n",
    "## 7.3: post a message\n",
    "\n",
    "use the `alarm_clock.py` file to post a message to that new bucket you created in the previous step.\n",
    "\n",
    "\n",
    "## 7.4: send us some proof!\n",
    "\n",
    "email us the command you wrote to use `alarm_clock.py` to upload a message as a file to `s3`, and send us the link to the resulting file. verify that the `url` works for other users by opening an incognito browser accessing it (this way you will certainly not be logged in to the `aws` web console).\n",
    "\n",
    "\n",
    "##### include a single `bash` command and a `url` in your submission email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 8: encrypting password with `kms` encryption\n",
    "\n",
    "in the `s3` lecture, I mentioned that `s3` supports *server-side* encryption as a simple check box (that is, whenever a file is received by `s3` it will encrypt it (jumble the contents so they are unreadable to a human) with a secret key, and it will decrypt that file (reverse that jumbling) whenver someone who is approved (e.g. *you*) requests that file. I also mentioned that *client-side* encryption -- where you as a user jumble the contents before you even send them to `s3`, and decrypt the jumbled contents when they're sent back to you -- is another option, but it requires extra effort, and I didn't elaborate on that extra effort.\n",
    "\n",
    "before that, in the web scraping lectures, I mentioned that it might be possible to store an *encrypted* (jumbled) version of a password in plain text on your local machine and that if you new how to *decrypt* (un-jumble) that encrypted version, and if so, that this would be more secure than saving the regular password in plain text with password protection. but I didn't discuss how you might do that at all.\n",
    "\n",
    "let's walk through how *client-side encryption* can be done relatively easily using the `aws kms` service and the `python` `boto3` library.\n",
    "\n",
    "the end result here will be a handful of `python` functions which can encrypt and decrypt messages, upload a secret message to `s3`, and download and decrypt that same message.\n",
    "\n",
    "\n",
    "## 8.1: create a kms key\n",
    "\n",
    "go to the `aws iam` web console page. the left-hand menu has, as one of its options, [\"Encryption Keys\"](https://console.aws.amazon.com/iam/home#/encryptionKeys/us-east-1). navigate to that place, and create a new key.\n",
    "\n",
    "+ pick an alias you can remember and easily type\n",
    "+ tag if you want!\n",
    "+ for the administrator, select your personal `iam` user.\n",
    "+ for the usage permissions, make sure to add the `iam` `role` you have given your `ec2` server\n",
    "    + we added this in the lecture on `aws` `cli`, but you can see it in the \"description\" window for your `ec2` server with a name \"IAM role\", or you can right click the `ec2` instance, select \"Instance Settings > Attach/Replace IAM Role\"\n",
    "\n",
    "\n",
    "## 8.2: encrypt a message\n",
    "\n",
    "let's assume that in the previous step your named your key `mykey` (replace all occurrences of `mykey` below with whatever you actually used for your key alias name).\n",
    "\n",
    "encrypting a message is simple with the `kms` client's `encrypt` method:\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "session = boto3.session.Session(region_name='us-east-1')\n",
    "\n",
    "message = b'evs'\n",
    "keyalias = 'mykey'\n",
    "\n",
    "# note: the kms service does not have a *resource* object yet, so we use a client\n",
    "kms = session.client('kms')\n",
    "\n",
    "response = kms.encrypt(\n",
    "    KeyId='alias/{}'.format(keyalias),\n",
    "    Plaintext=message,\n",
    ")\n",
    "\n",
    "encryptedmessage = response['CiphertextBlob']\n",
    "print(encryptedmessage)\n",
    "```\n",
    "\n",
    "if at any point you run into permissions issues, please resolve those issues using the `iam` service.\n",
    "\n",
    "\n",
    "## 8.3: write encrypted message to an `s3` file\n",
    "\n",
    "using the process we demoed in a mini-exercise in the `s3` lecture where we upload a *string* (not a local text file) into a file on `s3`, create a file on `s3` with the encrypted message as its contents.\n",
    "\n",
    "\n",
    "## 8.4: download that file from `s3`\n",
    "\n",
    "using the process we demoed in a mini-exercise in the `s3` lecture, download the file you just posted to `s3` into a string object (*i.e.* don't download to file).\n",
    "\n",
    "\n",
    "## 8.5: decrypt the message inside the downloaded file\n",
    "\n",
    "the `kms` client object you created above has a `decrypt` method function that take an encrypted message and cycles through your encryption keys until one of them successfully decrypts the string.\n",
    "\n",
    "apply that `kms.decrypt` function to the encrypted message you just downloaded\n",
    "\n",
    "```python\n",
    "import boto3\n",
    "\n",
    "session = boto3.session.Session(region_name='us-east-1')\n",
    "\n",
    "kms = session.client('kms')\n",
    "\n",
    "response = kms.decrypt(CiphertextBlob=encryptedmessage)\n",
    "decryptedmessage = response['Plaintext']\n",
    "print(decryptedmessage)\n",
    "```\n",
    "\n",
    "## 8.6: put it all together\n",
    "\n",
    "use the code you generated above to fill in the details of the `python` script `clientside.py`, available on my shared `s3` bucket here:\n",
    "\n",
    "https://s3.amazonaws.com/shared.rzl.gu511.com/clientside.py\n",
    "\n",
    "fill in the regions marked by comment boxes:\n",
    "\n",
    "```python\n",
    "# ---------------- #\n",
    "# FILL THIS IN !!! #\n",
    "# ---------------- #\n",
    "```\n",
    "\n",
    "## 8.7: validate your script\n",
    "\n",
    "if your script is working as expected, you should be able to do the following. in `python`:\n",
    "\n",
    "```python\n",
    "import clientside\n",
    "\n",
    "key_alias = 'YOUR_KEY_ALIAS'\n",
    "assert clientside.decrypt(clientside.encrypt('helloworld', key_alias), key_alias) == b'helloworld' \n",
    "```\n",
    "\n",
    "and from the command line\n",
    "\n",
    "```sh\n",
    "python clientside.py upload -k YOUR_KEY_ALIAS -m 'hello world' -b YOUR_BUCKET_NAME -s testencr.txt\n",
    "python clientside.py download -k YOUR_KEY_ALIAS -b YOUR_BUCKET_NAME -s testencr.txt\n",
    "b'hello world'\n",
    "```\n",
    "\n",
    "\n",
    "## 8.8: epilogue: application to passwords\n",
    "\n",
    "*you don't have to do the following: this is just an explanation of how you can use the above to work with passwords*\n",
    "\n",
    "in the \"encrypt a message\" section above, suppose the \"message\" you wanted to encrypt was a plain-text password you entered manually as\n",
    "\n",
    "```python\n",
    "import getpass\n",
    "\n",
    "message = getpass.getpass(prompt=\"Your Password: \")\n",
    "```\n",
    "\n",
    "you could now easily take that plain-text password and encrypt it. you could then quite easily write that encrypted password to a file anywhere on your computer -- say, `~/.secrets/mycredentials.json`.\n",
    "\n",
    "then, when you want to *use* that password, you could do the following with a `kms` client created the same way as above:\n",
    "\n",
    "```python\n",
    "encryptedPw = read_pw_from_file(\"/home/ubuntu/.secrets/mycredentials.json\")\n",
    "plaintextPw = kms.decrypt(CiphertextBlob=encryptedPw)['Plaintext']\n",
    "```\n",
    "\n",
    "not too much effort for a little extra security.\n",
    "\n",
    "\n",
    "##### upload your updated version of `clientside.py` to your `s3` homework submission bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercise 9: `merge` two `branch`es with overlapping edits to the same file: a `CONFLICT`!\n",
    "\n",
    "## 9.1: make a local update to `README.md`\n",
    "\n",
    "you, continuing your unblemished record of being astute and dilligent, notice that we never added a description of the `dspipeline.py` file to our `README.md`. you decide to update that.\n",
    "\n",
    "update `README.md` to read:\n",
    "\n",
    "```\n",
    "# 511 github repo\n",
    "\n",
    "the primary function of this repo is to develop `git` skills over the course of the year.\n",
    "\n",
    "## repository contents\n",
    "\n",
    "+ `helloworld.py`\n",
    "    + run with `python helloworld.py`\n",
    "    + this will greet you and then tell you the current time\n",
    "+ `rzl.py`\n",
    "    + run with `python rzl.py`\n",
    "    + this will offer you the ramblings of a teacher who thinks he is funnier than he is\n",
    "+ `dspipeline.py`\n",
    "    + a file containing some utilities for building data science pipelines, and an example that trains several models on adult salary data and selects the best based on cross validated metrics\n",
    "```\n",
    "\n",
    "\n",
    "## 9.2: update `master`\n",
    "\n",
    "`add` this change, `commit` it with a message `README: including dspipeline description`, and `push` to `github`\n",
    "\n",
    "\n",
    "## 9.3: fetch my new `branch`\n",
    "\n",
    "after pushing to `master` and checking on `github`, you notice that I have sneakily added my *own* updates to `README.md` as a new `branch` called `yolo`.\n",
    "\n",
    "use `git fetch --all` to create a mirror repository of that `branch`.\n",
    "\n",
    "*note: this branch will be pushed on Saturday afternoon to make sure all users have had time to update their `github` repos from the previous assignment*\n",
    "\n",
    "\n",
    "## 9.4: `merge` my changes in with yours\n",
    "\n",
    "use [`git merge`](https://git-scm.com/docs/git-merge) to `merge` the change that I made on the `yolo` branch into `master`. \n",
    "\n",
    "`git` will do it's `diff`-calculating magic and realize it can't simply combine the edits like it did last time. you get\n",
    "\n",
    "```sh\n",
    "git merge yolo\n",
    "```\n",
    "```\n",
    "Auto-merging README.md\n",
    "CONFLICT (content): Merge conflict in README.md\n",
    "Automatic merge failed; fix conflicts and then commit the result.\n",
    "```\n",
    "\n",
    "ugh seriously zach... it's just... like, some communication would be appreciated. some effort.\n",
    "\n",
    "\n",
    "## 9.5: resolve the `CONFLICT`\n",
    "\n",
    "if you check `git status` right now, you will be informed that there are conflicts in the `merge` process:\n",
    "\n",
    "```sh\n",
    "git merge\n",
    "```\n",
    "\n",
    "```\n",
    "On branch master\n",
    "Your branch is up to date with 'origin/master'.\n",
    "\n",
    "You have unmerged paths.\n",
    "  (fix conflicts and run \"git commit\")\n",
    "  (use \"git merge --abort\" to abort the merge)\n",
    "\n",
    "Unmerged paths:\n",
    "  (use \"git add <file>...\" to mark resolution)\n",
    "\n",
    "\tboth modified:   README.md\n",
    "\n",
    "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
    "```\n",
    "\n",
    "let's listen to `git` -- let's fix conflicts in our file and then `git commit`\n",
    "\n",
    "in an editor, open `README.md` and look for conflicts (demarked by `<<<<<<< HEAD` and `>>>>>>> yolo`). edit that entire section between those two pieces to include the lines that you think are appropriate (that is, yours).\n",
    "\n",
    "after you've edited, run `add` the edited `CONFLICT`-less file and `commit` it with message `README: zach is not even trying any more`\n",
    "\n",
    "\n",
    "`push` the updated `master` `branch` to `github`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
